import json
import logging
import re
from typing import Any

from openai.types.chat.chat_completion import ChatCompletion

from astrbot.api.event import AstrMessageEvent, filter
from astrbot.api.provider import LLMResponse
from astrbot.api.star import Context, Star

try:
    # è°¨æ…å¼•å…¥ï¼Œé¿å…åœ¨æœªå®‰è£… google-genai çš„ç¯å¢ƒä¸‹æŠ¥é”™
    from google.genai.types import GenerateContentResponse
except Exception:  # pragma: no cover - å…¼å®¹æ— æ­¤ä¾èµ–çš„è¿è¡Œç¯å¢ƒ
    GenerateContentResponse = None  # type: ignore


class R1Filter(Star):
    def __init__(self, context: Context):
        super().__init__(context)

    @filter.on_llm_response()
    async def resp(self, event: AstrMessageEvent, response: LLMResponse):
        cfg = self.context.get_config(umo=event.unified_msg_origin).get(
            "provider_settings",
            {},
        )
        show_reasoning = cfg.get("display_reasoning_text", False)

        # --- Gemini: è¿‡æ»¤/å±•ç¤º thought:true ç‰‡æ®µ ---
        # Gemini å¯èƒ½åœ¨ parts ä¸­æ³¨å…¥ {"thought": true, "text": "..."}
        # å®˜æ–¹ SDK é»˜è®¤ä¸ä¼šè¿”å›æ­¤å­—æ®µã€‚
        if GenerateContentResponse is not None and isinstance(
            response.raw_completion,
            GenerateContentResponse,
        ):
            thought_text, answer_text = self._extract_gemini_texts(
                response.raw_completion,
            )

            if thought_text or answer_text:
                # æœ‰æ˜ç¡®çš„æ€è€ƒ/æ­£æ–‡åˆ†ç¦»ä¿¡å·ï¼Œåˆ™æŒ‰é…ç½®å¤„ç†
                if show_reasoning:
                    merged = (
                        (f"ğŸ¤”æ€è€ƒï¼š{thought_text}\n\n" if thought_text else "")
                        + (answer_text or "")
                    ).strip()
                    if merged:
                        response.completion_text = merged
                        return
                # é»˜è®¤éšè—æ€è€ƒå†…å®¹ï¼Œä»…ä¿ç•™æ­£æ–‡
                elif answer_text:
                    response.completion_text = answer_text
                    return

        # --- é Gemini æˆ–æ— æ˜ç¡® thought:true æƒ…å†µ ---
        if show_reasoning:
            # æ˜¾ç¤ºæ¨ç†å†…å®¹çš„å¤„ç†é€»è¾‘
            if (
                response
                and response.raw_completion
                and isinstance(response.raw_completion, ChatCompletion)
                and len(response.raw_completion.choices) > 0
                and response.raw_completion.choices[0].message
            ):
                message = response.raw_completion.choices[0].message
                reasoning_content = ""  # åˆå§‹åŒ– reasoning_content

                # æ£€æŸ¥ Groq deepseek-r1-distill-llama-70b æ¨¡å‹çš„ 'reasoning' å±æ€§
                if hasattr(message, "reasoning") and message.reasoning:
                    reasoning_content = message.reasoning
                # æ£€æŸ¥ DeepSeek deepseek-reasoner æ¨¡å‹çš„ 'reasoning_content'
                elif (
                    hasattr(message, "reasoning_content") and message.reasoning_content
                ):
                    reasoning_content = message.reasoning_content

                if reasoning_content:
                    response.completion_text = (
                        f"ğŸ¤”æ€è€ƒï¼š{reasoning_content}\n\n{message.content}"
                    )
                else:
                    response.completion_text = message.content
        else:
            # è¿‡æ»¤æ¨ç†æ ‡ç­¾çš„å¤„ç†é€»è¾‘
            completion_text = response.completion_text

            # æ£€æŸ¥å¹¶ç§»é™¤ <think> æ ‡ç­¾
            if r"<think>" in completion_text or r"</think>" in completion_text:
                # ç§»é™¤é…å¯¹çš„æ ‡ç­¾åŠå…¶å†…å®¹
                completion_text = re.sub(
                    r"<think>.*?</think>",
                    "",
                    completion_text,
                    flags=re.DOTALL,
                ).strip()

                # ç§»é™¤å¯èƒ½æ®‹ç•™çš„å•ä¸ªæ ‡ç­¾
                completion_text = (
                    completion_text.replace(r"<think>", "")
                    .replace(r"</think>", "")
                    .strip()
                )

            response.completion_text = completion_text

    # ------------------------
    # helpers
    # ------------------------
    def _get_part_dict(self, p: Any) -> dict:
        """ä¼˜å…ˆä½¿ç”¨ SDK æ ‡å‡†åºåˆ—åŒ–æ–¹æ³•è·å–å­—å…¸ï¼Œå¤±è´¥åˆ™é€çº§å›é€€ã€‚

        é¡ºåº: model_dump â†’ model_dump_json â†’ json â†’ to_dict â†’ dict â†’ __dict__ã€‚
        """
        for getter in ("model_dump", "model_dump_json", "json", "to_dict", "dict"):
            fn = getattr(p, getter, None)
            if callable(fn):
                try:
                    result = fn()
                    if isinstance(result, (str, bytes)):
                        try:
                            if isinstance(result, bytes):
                                result = result.decode("utf-8", "ignore")
                            return json.loads(result) or {}
                        except json.JSONDecodeError:
                            continue
                    if isinstance(result, dict):
                        return result
                except (AttributeError, TypeError):
                    continue
                except Exception as e:
                    logging.exception(
                        f"Unexpected error when calling {getter} on {type(p).__name__}: {e}",
                    )
                    continue
        try:
            d = getattr(p, "__dict__", None)
            if isinstance(d, dict):
                return d
        except (AttributeError, TypeError):
            pass
        except Exception as e:
            logging.exception(
                f"Unexpected error when accessing __dict__ on {type(p).__name__}: {e}",
            )
        return {}

    def _is_thought_part(self, p: Any) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ€è€ƒç‰‡æ®µã€‚

        è§„åˆ™:
        1) ç›´æ¥ thought å±æ€§
        2) å­—å…¸å­—æ®µ thought æˆ– metadata.thought
        3) data/raw/extra/_raw ä¸­åµŒå…¥çš„ JSON ä¸²åŒ…å« thought: true
        """
        try:
            if getattr(p, "thought", False):
                return True
        except Exception:
            # best-effort
            pass

        d = self._get_part_dict(p)
        if d.get("thought") is True:
            return True
        meta = d.get("metadata")
        if isinstance(meta, dict) and meta.get("thought") is True:
            return True
        for k in ("data", "raw", "extra", "_raw"):
            v = d.get(k)
            if isinstance(v, (str, bytes)):
                try:
                    if isinstance(v, bytes):
                        v = v.decode("utf-8", "ignore")
                    parsed = json.loads(v)
                    if isinstance(parsed, dict) and parsed.get("thought") is True:
                        return True
                except json.JSONDecodeError:
                    continue
        return False

    def _extract_gemini_texts(self, resp: Any) -> tuple[str, str]:
        """ä» GenerateContentResponse ä¸­æå– (æ€è€ƒæ–‡æœ¬, æ­£æ–‡æ–‡æœ¬)ã€‚"""
        try:
            cand0 = next(iter(getattr(resp, "candidates", []) or []), None)
            if not cand0:
                return "", ""
            content = getattr(cand0, "content", None)
            parts = getattr(content, "parts", None) or []
        except (AttributeError, TypeError, ValueError):
            return "", ""

        thought_buf: list[str] = []
        answer_buf: list[str] = []
        for p in parts:
            txt = getattr(p, "text", None)
            if txt is None:
                continue
            txt_str = str(txt).strip()
            if not txt_str:
                continue
            if self._is_thought_part(p):
                thought_buf.append(txt_str)
            else:
                answer_buf.append(txt_str)

        return "\n".join(thought_buf).strip(), "\n".join(answer_buf).strip()
